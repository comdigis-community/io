{"kind":"article","variants":[{"paths":["\/documentation\/io\/io"],"traits":[{"interfaceLanguage":"swift"}]}],"primaryContentSections":[{"kind":"content","content":[{"text":"Overview","anchor":"overview","level":2,"type":"heading"},{"inlineContent":[{"type":"text","text":"Thanks for taking the time to explore "},{"inlineContent":[{"text":"I\/O","type":"text"}],"type":"strong"},{"type":"text","text":". Purposefully designed around a modular and extensible audio-processing graph (DAG), the framework structures synthesis, processing, analysis, and rendering into well-defined nodes that communicate through a stable and deterministic data flow. This community edition introduces the essential foundations, offering a clear and approachable entry point into its core concepts and capabilities."}],"type":"paragraph"},{"inlineContent":[{"type":"image","identifier":"IO.png"}],"type":"paragraph"},{"text":"Getting Started","anchor":"Getting-Started","level":4,"type":"heading"},{"inlineContent":[{"type":"text","text":"This document provides a concise technical overview to help you understand and use "},{"inlineContent":[{"text":"I\/O","type":"text"}],"type":"strong"},{"type":"text","text":", our multiplatform audio development environment. Designed for both flexibility and performance, "},{"inlineContent":[{"text":"I\/O","type":"text"}],"type":"strong"},{"type":"text","text":" offers a unified suite of tools for integrating audio sources, applying advanced effects, generating detailed visualizations, and constructing dynamic routing strategies."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"At the core of the system are "},{"inlineContent":[{"text":"nodes","type":"text"}],"type":"strong"},{"type":"text","text":", which connect to form a "},{"inlineContent":[{"text":"processing graph","type":"text"}],"type":"strong"},{"type":"text","text":". These nodes can be assembled into simple linear chains or more elaborate structures, allowing you to define custom signal paths that adapt to a wide range of creative or technical requirements."}],"type":"paragraph"},{"style":"note","content":[{"inlineContent":[{"text":"","type":"text"},{"text":" ","type":"text"},{"text":"Processing begins with a source delivering samples at extremely small time intervals — often tens of thousands per second. Each node receives, transforms, and optionally forwards these samples to other nodes, enabling highly modular and sophisticated routing schemes.","type":"text"}],"type":"paragraph"}],"name":"Implementation","type":"aside"},{"type":"thematicBreak"},{"text":"Binaural Audio","anchor":"Binaural-Audio","level":4,"type":"heading"},{"inlineContent":[{"inlineContent":[{"text":"Spatial audio","type":"text"}],"type":"strong"},{"type":"text","text":" extends traditional reproduction by simulating how we perceive acoustic space — introducing depth, elevation, motion, and environmental cues. Methods such as binaural rendering and object-based processing combine acoustics, psychoacoustics, and advanced DSP to create immersive experiences across diverse playback environments."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"One of the most widely used approaches to spatial audio is "},{"inlineContent":[{"text":"binaural rendering","type":"text"}],"type":"strong"},{"type":"text","text":"."}],"type":"paragraph"},{"type":"video","identifier":"IO.mp4"},{"text":"Binaural Renderer","type":"heading","anchor":"Binaural-Renderer","level":4},{"type":"paragraph","inlineContent":[{"text":"This technique simulates how the ears, head, and torso alter sound propagation before it reaches the eardrums. This behavior—captured by the head-related transfer function ","type":"text"},{"inlineContent":[{"text":"(HRTF)","type":"text"}],"type":"emphasis"},{"text":"—is essential for reconstructing immersive sound fields with convincing depth, height, movement, and precise spatial localization.","type":"text"}]},{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"text":"I\/O","type":"text"}]},{"text":" uses a unified listener representation that defines the listening position and orientation through three vectors: ","type":"text"},{"type":"strong","inlineContent":[{"type":"text","text":"position"}]},{"text":", ","type":"text"},{"type":"strong","inlineContent":[{"text":"forward","type":"text"}]},{"text":", and ","type":"text"},{"type":"strong","inlineContent":[{"text":"up","type":"text"}]},{"text":". The listener provides the reference frame for all spatial calculations, and its parameters — such as the speed of sound or ","type":"text"},{"type":"strong","inlineContent":[{"type":"text","text":"Doppler"}]},{"text":" — can be updated dynamically to remain coherent with the physical environment.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Both listeners and sources operate in Cartesian coordinates, where the positive ","type":"text"},{"type":"strong","inlineContent":[{"type":"text","text":"Y"}]},{"text":" axis points upward. Magnitudes remain consistent with physical units, ensuring predictable interpretation across different rendering contexts.","type":"text"}]},{"name":"Documentation","content":[{"type":"paragraph","inlineContent":[{"type":"text","text":""},{"type":"text","text":" "},{"text":"For additional technical details, refer to the ","type":"text"},{"type":"reference","isActive":true,"identifier":"doc:\/\/io.IO\/documentation\/IO\/Binaural"},{"type":"text","text":" specification."}]}],"type":"aside","style":"note"},{"type":"thematicBreak"},{"type":"paragraph","inlineContent":[{"text":"Copyright © 2019–2027 — ","type":"text"},{"inlineContent":[{"inlineContent":[{"text":"Comdigis","type":"text"}],"type":"strong"}],"type":"emphasis"},{"text":", Buenos Aires, Argentina","type":"text"}]}]}],"hierarchy":{"paths":[["doc:\/\/io.IO\/documentation\/IO"]]},"abstract":[{"text":"Engineering audio experiences for creators","type":"text"}],"metadata":{"roleHeading":"Article","modules":[{"name":"IO"}],"role":"article","title":"Introduction"},"sections":[],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/io.IO\/documentation\/IO\/IO"},"schemaVersion":{"minor":3,"patch":0,"major":0},"references":{"doc://io.IO/documentation/IO":{"role":"collection","abstract":[],"type":"topic","kind":"symbol","url":"\/documentation\/io","title":"IO","identifier":"doc:\/\/io.IO\/documentation\/IO"},"IO.mp4":{"poster":"IO+.png","alt":"I\/O","type":"video","identifier":"IO.mp4","variants":[{"traits":["1x","light"],"url":"\/videos\/io.IO\/IO.mp4"}]},"IO.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/io.IO\/IO.png"}],"alt":"I\/O","identifier":"IO.png","type":"image"},"doc://io.IO/documentation/IO/Binaural":{"navigatorTitle":[{"kind":"identifier","text":"Binaural"}],"kind":"symbol","role":"symbol","type":"topic","title":"Binaural","url":"\/documentation\/io\/binaural","fragments":[{"kind":"keyword","text":"class"},{"kind":"text","text":" "},{"kind":"identifier","text":"Binaural"}],"abstract":[{"text":"Specifies a ","type":"text"},{"type":"emphasis","inlineContent":[{"text":"binaural","type":"text"}]},{"text":" spatializer that applies occlusion.","type":"text"}],"identifier":"doc:\/\/io.IO\/documentation\/IO\/Binaural"},"IO+.png":{"variants":[{"traits":["1x","light"],"url":"\/images\/io.IO\/IO+.png"}],"alt":null,"identifier":"IO+.png","type":"image"}}}